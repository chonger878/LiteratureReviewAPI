{"&cites=3166990653379142174&as_sdt=2005&sciodt=0,5&hl=en":[{"title":"Recent trends in deep learning based natural language processing","url":"https://ieeexplore.ieee.org/abstract/document/8416973/","authors":["T Young","T Young D Hazarika","T Young D Hazarika S Poria…"],"year":2018,"numCitations":882,"pdf":"https://arxiv.org/pdf/1708.02709","citationUrl":"http://scholar.google.com/scholar?cites=3050905065745226465&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:4RovL_79VioJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=3050905065745226465&hl=en&as_sdt=2005&sciodt=0,5","publication":"ieeexplore.ieee.org","p":1,"exp":1595840038119},{"title":"Xlnet: Generalized autoregressive pretraining for language understanding","url":"http://papers.nips.cc/paper/8812-xlnet-generalized-autoregressive-pretraining-for-language-understanding","authors":["Z Yang","Z Yang Z Dai","Z Yang Z Dai Y Yang","Z Yang Z Dai Y Yang J Carbonell…"],"year":2019,"numCitations":977,"pdf":"https://papers.nips.cc/paper/8812-xlnet-generalized-autoregressive-pretraining-for-language-understanding.pdf","citationUrl":"http://scholar.google.com/scholar?cites=14487406216105917109&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:tXrHKzKbDckJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=14487406216105917109&hl=en&as_sdt=2005&sciodt=0,5","publication":"papers.nips.cc"},{"title":"Language models are unsupervised multitask learners","url":"https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/PAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask-%20Learners.pdf","authors":["A Radford","A Radford J Wu","A Radford J Wu R Child","A Radford J Wu R Child D Luan","A Radford J Wu R Child D Luan D Amodei…"],"year":2019,"numCitations":612,"pdf":"https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/PAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask-%20Learners.pdf","citationUrl":"http://scholar.google.com/scholar?cites=8489993790021660506&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:Wm-Dv16E0nUJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=8489993790021660506&hl=en&as_sdt=2005&sciodt=0,5","publication":"ceid.upatras.gr"},{"title":"Transformer-xl: Attentive language models beyond a fixed-length context","url":"https://arxiv.org/abs/1901.02860","authors":["Z Dai","Z Dai Z Yang","Z Dai Z Yang Y Yang","Z Dai Z Yang Y Yang J Carbonell","Z Dai Z Yang Y Yang J Carbonell QV Le…"],"year":2019,"numCitations":484,"pdf":"https://arxiv.org/pdf/1901.02860.pdf?fbclid=IwAR3nwzQA7VyD36J6u8nEOatG0CeW4FwEU_upvvrgXSES1f0Kd-xGTS0MFfY","citationUrl":"http://scholar.google.com/scholar?cites=7150055013029036741&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:xcIY2CYZOmMJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=7150055013029036741&hl=en&as_sdt=2005&sciodt=0,5","publication":"arxiv.org"},{"title":"BioBERT: a pre-trained biomedical language representation model for biomedical text mining","url":"https://academic.oup.com/bioinformatics/article-abstract/36/4/1234/5566506","authors":["J Lee","J Lee W Yoon","J Lee W Yoon S Kim","J Lee W Yoon S Kim D Kim","J Lee W Yoon S Kim D Kim S Kim","J Lee W Yoon S Kim D Kim S Kim CH So…"],"year":2020,"numCitations":349,"pdf":"https://academic.oup.com/bioinformatics/article/36/4/1234/5566506","citationUrl":"http://scholar.google.com/scholar?cites=2783127196632783403&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:K5oGkHCnnyYJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=2783127196632783403&hl=en&as_sdt=2005&sciodt=0,5","publication":"academic.oup.com"},{"title":"Cross-lingual language model pretraining","url":"https://arxiv.org/abs/1901.07291","authors":["G Lample","G Lample A Conneau"],"year":2019,"numCitations":296,"pdf":"https://arxiv.org/pdf/1901.07291","citationUrl":"http://scholar.google.com/scholar?cites=11542237222100207278&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:rgaToJlDLqAJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=11542237222100207278&hl=en&as_sdt=2005&sciodt=0,5","publication":"arxiv.org"},{"title":"Albert: A lite bert for self-supervised learning of language representations","url":"https://arxiv.org/abs/1909.11942","authors":["Z Lan","Z Lan M Chen","Z Lan M Chen S Goodman","Z Lan M Chen S Goodman K Gimpel…"],"year":2019,"numCitations":310,"pdf":"https://arxiv.org/pdf/1909.11942.pdf?fbclid=IwAR1gWlaWokv7Ys5JNkTgQ3Hw-wdvwv9J5zkYE1-N0lHbqiAOlvJTfhaKuDg","citationUrl":"http://scholar.google.com/scholar?cites=6606720413006378435&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:wzWRMzbJr1sJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=6606720413006378435&hl=en&as_sdt=2005&sciodt=0,5","publication":"arxiv.org"},{"title":"Coqa: A conversational question answering challenge","url":"https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00266","authors":["S Reddy","S Reddy D Chen","S Reddy D Chen CD Manning"],"year":2019,"numCitations":250,"pdf":"https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00266","citationUrl":"http://scholar.google.com/scholar?cites=783716453669313794&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:Ap2WWfZR4AoJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=783716453669313794&hl=en&as_sdt=2005&sciodt=0,5","publication":"MIT Press"},{"title":"Multi-task deep neural networks for natural language understanding","url":"https://arxiv.org/abs/1901.11504","authors":["X Liu","X Liu P He","X Liu P He W Chen","X Liu P He W Chen J Gao"],"year":2019,"numCitations":255,"pdf":"https://arxiv.org/pdf/1901.11504","citationUrl":"http://scholar.google.com/scholar?cites=7022248125389648461&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:TbKA7nYJdGEJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=7022248125389648461&hl=en&as_sdt=2005&sciodt=0,5","publication":"arxiv.org"},{"title":"Roberta: A robustly optimized bert pretraining approach","url":"https://arxiv.org/abs/1907.11692","authors":["Y Liu","Y Liu M Ott","Y Liu M Ott N Goyal","Y Liu M Ott N Goyal J Du","Y Liu M Ott N Goyal J Du M Joshi","Y Liu M Ott N Goyal J Du M Joshi D Chen…"],"year":2019,"numCitations":284,"pdf":"https://arxiv.org/pdf/1907.11692","citationUrl":"http://scholar.google.com/scholar?cites=12744939629894656578&as_sdt=2005&sciodt=0,5&hl=en","relatedUrl":"http://scholar.google.com/scholar?q=related:QmKrWxEf37AJ:scholar.google.com/&scioq=&hl=en&as_sdt=2005&sciodt=0,5","urlVersionsList":"http://scholar.google.com/scholar?cluster=12744939629894656578&hl=en&as_sdt=2005&sciodt=0,5","publication":"arxiv.org"}]}